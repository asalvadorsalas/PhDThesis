Proton collisions are complex processes and their understanding is essential to interpret the experimental data from the LHC. Normally, physics analyses rely on the ability to accurately simulate the various processes of proton-proton collisions and the interactions with the detector in order to perform comparisons with the recorded data and quantify its the level of agreement of the SM. The simulation is usually performed with Monte Carlo generators, which are stochastic tools that incorporate both theoretical predictions and empirical results to describe the statistical processes.
Sections bla and bla 

\section{Event simulation}

The typical proton-proton collision at the LHC is depicted in \textcolor{red}{Figure}. The inelastic scattering is the main interesting process, where the energy of the system is large enough so a constituent of each proton (partons), interacts and allows the production of additional particles. The interaction that involves any of the other partons, normally at lower energies, is referred to as underlying event. A key phenomenon is the parton shower, a processes where due to the strong interaction, particles loose energy due the radiation of gluons which further generate quark-antiquark pairs, which in turn radiate gluons again in a chain reaction. These generated particles loose energy progressively down to the point where QCD leaves the perturbative regime ($\sim$1~GeV) and the hadronisation occurs, when quarks and gluons form hadrons, colorless bound states. To complete the simulation of the collision, the pile-up is included which adds the effects from the other proton collisions that originate from the same or previous bunch-crossing.  

\subsection{Factorisation theorem}

The cross-section of the hard scattering between partons inside of the proton producing a final stat $X$, $\sigma_{pp\to X}$ can be factorised into two components in perturbation theory, as the strong coupling constant, $\alpha_s$, is small at high energy kinematic regimes. Using the factorisation theorem \textcolor{red}{cite},

\begin{equation}
    \sigma_{pp\to X}=\sum_{a,b}\int \text{d}x_a\text{d}x_b f_a(x_a,\mu_F^2)f_b(x_b,\mu_F^2)\cdot\hat{\sigma}_{ab\to X}(x_a p_a,x_b p_b,\mu_F^2,\mu_R^2),
\end{equation}

where $f_i(x_i,\mu_F^2)$ are the \acrlong{PDFlabel}~(\acrshort{PDFlabel}) for partons $i=a,b\in\left\{g, u, \bar{u}, d, ...\right\}$ and encodes the probability of finding a parton of type $i$ within the proton carrying a fraction of the proton's momentum $x_i$, at the factorisation scale $\mu_F$. The dependance of the scale appears from performing only fixed-order calculations and the value is typically set comparable to the energy of the process, for example, to the total transverse mass of the final-state particles. The partonic cross-section, $\hat{\sigma}_{ab\to X}(x_a p_a,x_b p_b,\mu_F^2,\mu_R^2)$, is calculated at finite perturbative order, hence the additional dependance on the renormalisation scale, $\mu_R$, at which to evaluate $\alpha_s$.

\subsection{Parton density function}

The \acrshort{PDFlabel}s are crucial for the accurate description of the partons that form the protons. The first type of partons are the valence quarks which determine the quantum numbers of the proton. In addition, gluons and virtual quark-antiquark pairs (sea-quarks) are also part of the proton and come from the vaccum fluctuations. A \acrshort{PDFlabel}, $f_i^A(x_i,Q^2)$ describres the probability density of a parton of a certain type, $i$, inside a given hadron, $A$ to carry a certain momentum fraction, $x=p_i/p_A$ evaluated at a specific momentun transfer $Q^2$. In general, \acrshort{PDFlabel} are excracted from empirical measurements performed at a specific scale. Then, the \acrlong{DGLAPlabel}~(\acrshort{DGLAPlabel}) equations are used to extrapolate the \acrshort{PDFlabel} to different scales. Other alternatives to extract the functions like latice \acrshort{QCD} are possible, but very computationally challenging. %https://arxiv.org/abs/2005.02102 
There are dedicated collaborations such as the \textit{NNPDF}, \textit{CTEQ} and \textit{MSTW} that provide %https://arxiv.org/abs/1410.8849 https://arxiv.org/abs/hep-ph/0508110 https://arxiv.org/abs/0901.0002
 \acrshort{PDFlabel}s for physics analyses. \textcolor{red}{Figure} shows the \textit{NNPDF3.0NLO} \acrshort{PDFlabel} set for the different proton partons and two different factorisation scales.

 There are two main factorisation schemes to describe processes involving $b$-quarks: the \acrlong{4FSlabel}~(\acrshort{4FSlabel}) and the \acrlong{5FSlabel}~(\acrshort{5FSlabel}). The \acrshort{4FSlabel} treats the $b$-quarks massive ($m_b>\mu_R$) and since $m_b>m_p$, they are not included in the sea of quarks and do not have an associated \acrshort{PDFlabel}. In the context of \acrshort{QCD} perturbative evolution, one of the consequences is that calculations at lower scales $\mu_R<m_b$ are especially impacted as the $\alpha_s$ running depends on the number of quark flavours in the initial state, $n_f=4$ \todo{reference euqation of the running}. On the other hand, at high scales the mass effects are negligible and usually described by the \acrshort{5FSlabel}, in which the $b$-quark is considered massless, included in the initial state and treated as the other quarks, $n_f=5$. 


\subsection{Monte Carlo simulation and generators}

The simulation 

Typically, the event generation is divided into two steps: the matrix element (ME) generation and the parton shower (PS) evolution and hadronisation modelling. 
describing the hard scattering and secondly the parton shower (PS) evolution and hadronisation modelling including initial state radiation (ISR) and final state radiation (FSR). While the ME and most
parts of the PS can be calculated perturbatively, the other processes are non-perturbative. A simplified
illustration of this full simulation process is shown in Figure 4.2. For the modelling of the hadronisation, there are different models, the most widely used models are: the Lund string model [81] and
the cluster model [82]. In the Lund string model, the colour connection of a quark-antiquark pair is
described as a string and the potential between them is assumed to be linearly increasing with their
distance. The strings then split according to a fragmentation function forming new quark-antiquark
pairs which continues until only hadrons with on-shell mass remain. The cluster model is based on
QCD pre-confinement, where neighbouring partons build colour-singlet clusters, these clusters then
decay into two hadrons and they then decay further until the final state hadrons are formed.

The full process involving matrix element generation, parton shower, underlying event, hadronisation and fragmentation can be simulated by MC generators like PYTHIA8 [84], HERWIG7 [85, 86]
or SHERPA [87]. However, PYTHIA8 provides mainly leading order calculations which are often not
sufficient since the next-to-leading order (NLO) corrections can be fairly large. HERWIG7 provides
many MEs also at NLO. Since the fraction of negative event weights can be quite large (up to
∼ 40% for certain generator setups), the generator is only used as parton shower in this thesis. In fact,
there are other generators like POWHEGBOX [88–92] or MADGRAPH5_aMC@NLO [93] providing
higher-order calculations which can be interfaced with PYTHIA8 or HERWIG7 for the simulation of
PS and hadronisation.
Furthermore, the models used to describe the non-perturbative processes have parameters that can
be tuned using collision data. The most common tunes used by the ATLAS experiment are the A14
parameters [94] for PYTHIA8 or the H7UE set of tuned parameters [86] for HERWIG7

Throughout this thesis the physics processes for proton-proton collisions at a centre-of-mass energy
√
s = 13 TeV are modelled using various combinations of MC generators and settings. The specific
details are stated in the dedicated chapters. Nevertheless, all MC samples using PYTHIA8 or HERWIG7 to model the multi-parton interaction (MPI), hadronisation and PS use the same settings if not
differently stated. The mass of the top quark is set to mt = 172.5 GeV, the Higgs boson mass to
mH = 125 GeV and the mass of the b-quark to mb = 4.8 GeV for PYTHIA8, to mb = 4.5 GeV for
HERWIG7 and to mb = 4.75 GeV for SHERPA. The simulation of b- and c-hadron decays is performed via the EVTGEN v1.6.0 program [95] with the exception of SHERPA. As mentioned above
the two tunes A14 combined with the NNPDF2.3LO PDF set [96] and H7UE together with the set
of MMHT2014LO PDFs [97] are used for PYTHIA8 and HERWIG7, respectivel


\section{Detector simulation}

The last step in the simulation chain is the detector simulation. The MC generators, as described
in Section 4.1, provide information about stable particles in the final state, not taking into account
the detector response. The full ATLAS detector simulation [98] is performed in two steps. The
first step is based on GEANT4 [99] incorporating the geometry of the detector and providing highly
precise modelling of the particle interactions with the detector matter. However, it comes with the
shortcoming of using a large fraction of the available computing power of ATLAS. As an alternative,
fast calorimeter simulation algorithms [100–102] are developed and already used in practice. They
mimic the GEANT4 results, based on thousands of individual parametrisations of the calorimeter
response, using significantly less computing resources with a trade-off in precision. A comparison
of the necessary CPU time for the different detector simulations are shown in Figure 4.3. In practice,

he fast simulation algorithms are widely used in ATLAS and are called AtlFast-II. In the second
step, the readout electronics and digitisation is simulated which is adjusted for the different detector
systems.
Taking advantage of the latest machine learning developments in the last years, deep generative
algorithms such as Generative Adversarial Networks (GANs) and Variational Auto-Encoders (VAEs)
are studied to improve the fast calorimeter simulation [103] showing already promising results.
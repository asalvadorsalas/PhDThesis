Proton collisions are complex processes and their understanding is essential to interpret the experimental data from the \acrshort{LHClabel}. Normally, physics analyses rely on the ability to accurately simulate the various processes of proton-proton collisions and the interactions with the detector in order to perform comparisons with the recorded data and quantify its the level of agreement of the SM. The simulation is usually performed with Monte Carlo \acrlong{MClabel}~(\acrshort{MClabel}) generators, which are stochastic tools that incorporate both theoretical predictions and empirical results to describe the statistical processes.
Sections bla and bla 

\section{Event simulation}

The typical proton-proton collision at the LHC is depicted in \textcolor{red}{Figure}. The inelastic scattering is the main interesting process, where the energy of the system is large enough so a constituent of each proton (partons) interact and allow the production of additional particles. The interaction that involves any of the other partons, normally at lower energies, is referred to as underlying event. A key phenomenon is the parton shower, a processes where due to the strong interaction, particles loose energy due the radiation of gluons which further generate quark-antiquark pairs, which in turn radiate gluons again in a chain reaction. These generated particles loose energy progressively down to the point where \acrshort{QCD} leaves the perturbative regime ($\sim$1~GeV) and the hadronisation occurs, when quarks and gluons form hadrons, colorless bound states. To complete the simulation of the collision, the pile-up is included which adds the effects from the other proton collisions that originate from the same or previous bunch-crossing.  

\subsection{Factorisation theorem}

The cross-section to produce a final stat $X$ from the hard scattering of two protons, $\sigma_{pp\to X}$ can be factorised into two components in perturbation theory, as the strong coupling constant, $\alpha_s$, is small at high energy kinematic regimes. Using the factorisation theorem \textcolor{red}{cite},

\begin{equation}
    \sigma_{pp\to X}=\sum_{a,b}\int \text{d}x_a\text{d}x_b f_a(x_a,\mu_F^2)f_b(x_b,\mu_F^2)\cdot\hat{\sigma}_{ab\to X}(x_a p_a,x_b p_b,\mu_F^2,\mu_R^2),
\end{equation}

where $f_i(x_i,\mu_F^2)$ are the \acrlong{PDFlabel}~(\acrshort{PDFlabel}) for partons $i=a,b\in\left\{g, u, \bar{u}, d, ...\right\}$ and encodes the probability of finding a parton of type $i$ within the proton carrying a fraction of the proton's momentum $x_i$, at the factorisation scale $\mu_F$. The dependence of the scale appears from performing only fixed-order calculations and the value is typically set comparable to the energy of the process, for example, to the total transverse mass of the final-state particles. The partonic cross-section, $\hat{\sigma}_{ab\to X}(x_a p_a,x_b p_b,\mu_F^2,\mu_R^2)$, is calculated at finite perturbative order, hence the additional dependence on the renormalisation scale, $\mu_R$, at which to evaluate $\alpha_s$.

\subsection{Parton density function}

The \acrshort{PDFlabel}s are crucial for the accurate description of the partons that form the protons. The first type of partons are the valence quarks which determine the quantum numbers of the proton. In addition, gluons and virtual quark-antiquark pairs (sea-quarks) are also part of the proton and come from the vaccum fluctuations. A \acrshort{PDFlabel}, $f_i^A(x_i,Q^2)$ describres the probability density of a parton of a certain type, $i$, inside a given hadron, $A$ to carry a certain momentum fraction, $x=p_i/p_A$ evaluated at a specific momentun transfer $Q^2$. In general, \acrshort{PDFlabel} are excracted from empirical measurements performed at a specific scale. Then, the \acrlong{DGLAPlabel}~(\acrshort{DGLAPlabel}) equations are used to extrapolate the \acrshort{PDFlabel} to different scales. Other alternatives to extract the functions like latice \acrshort{QCD} are possible, but very computationally challenging. %https://arxiv.org/abs/2005.02102 
There are dedicated collaborations such as the \textit{NNPDF}, \textit{CTEQ} and \textit{MSTW} that provide %https://arxiv.org/abs/1410.8849 https://arxiv.org/abs/hep-ph/0508110 https://arxiv.org/abs/0901.0002
 \acrshort{PDFlabel}s for physics analyses. \textcolor{red}{Figure} shows the \textit{NNPDF3.0NLO} \acrshort{PDFlabel} set for the different proton partons and two different factorisation scales.

 There are two main factorisation schemes to describe processes involving $b$-quarks: the \acrlong{4FSlabel}~(\acrshort{4FSlabel}) and the \acrlong{5FSlabel}~(\acrshort{5FSlabel}). The \acrshort{4FSlabel} treats the $b$-quarks massive ($m_b>\mu_R$) and since $m_b>m_p$, they are not included in the sea of quarks and do not have an associated \acrshort{PDFlabel}. In the context of \acrshort{QCD} perturbative evolution, one of the consequences is that calculations at lower scales $\mu_R<m_b$ are especially impacted as the $\alpha_s$ running depends on the number of quark flavours in the initial state, $n_f=4$ \todo{reference euqation of the running}. On the other hand, at high scales the mass effects are negligible and usually described by the \acrshort{5FSlabel}, in which the $b$-quark is considered massless, included in the initial state and treated as the other quarks, $n_f=5$. 

\subsection{Matrix element}

The computation of the partonic cross-section of partons $i,j$ into an arbritrary final state $X$, is related to the \acrshort{MElabel} amplitude as,

\begin{equation}
    \hat{\sigma}_{ij\to X} \sim \sum_{k=0}^{\infty} \int \text{d}\Phi_{X+k}\left|\sum_{l=0}^{\infty} M^l_{X+k}\right|^2(\Phi_F,\mu_F,\mu_R)
\end{equation}

were \acrshort{PDFlabel}s and other normalisation factors are removed for compactness. $M^l_{X+k}$ is the \acrshort{MElabel} amplitude for the production of $X$ in association with $k$ additional final-state partons, or legs, and with $l$ additional loop corrections. In a perturbative regime, the \acrshort{MElabel} amplitudes for increasingly complex processes (diagrams with additional legs and loops) tend to decrease. As a result, the cross-section is generally computed at a perturbative order, without the sum computed to infinity and for a choice of $\mu_F$ and $\mu_R$. The \acrlong{LOlabel}~(\acrshort{LOlabel}) is the lowest possible order for the calculation, with $k=l=0$. Next, $l=0,k=n$ provides the \acrshort{LOlabel} computation for the production of $X+n$ jets. Finally, $k+l\leq n$ corresponds to a N$^n$LO prediction for the production of $X$, while also to a N$^{n-k}$LO prediction for the production of $X$ in association of $k$ jets.

\subsection{Parton shower}

One problem that arises in the fixed order computations of the differential cross-section is the appearance of logarithmic divergences from collinear splitting that originate from the integration of the phase space, $\Phi$, of the additional $k$ partons. For an inclusive cross-section computation, these divergencies cancel out with virtual corrections order by order, following the KLN theorem. %https://aip.scitation.org/doi/10.1063/1.1724268 %https://journals.aps.org/pr/abstract/10.1103/PhysRev.133.B1549
In this case, the basic event is simulated at fixed order while the \acrshort{QCD} emission process (splitting) is computed with the \acrshort{PSlabel} algorithm, %https://www.sciencedirect.com/science/article/abs/pii/055032138090111X?via%3Dihub
which generates a sequence of emissions with decreasing angle or energy. The algorithm recursively produces the typical splitting processes ($g\to q\bar{q}$, $g\to gg$ and $q\to qg$) for each parton until the energy of the shower reaches $\sim$1~GeV, the hadronisation scale. This showering process that is applied to the final products after the hard-scattering is referred to as \acrlong{FSRlabel}~(\acrshort{FSRlabel}), while the simulation of the \acrlong{ISRlabel}~(\acrshort{ISRlabel}) is performed to the incoming partons. In the case of \acrshort{ISRlabel}, the subsequent emissions grow on energy and are modelled instead with a backwards-evolution algorithm. % https://www.sciencedirect.com/science/article/abs/pii/0370269385906744?via%3Dihub

There is an incompatibility with \acrshort{MElabel} and \acrshort{PSlabel} for a full cross-section computation at order $n>1$, as there is a possible overlap in the phase space of the extra partons that are considered for the \acrshort{MElabel} at order $n$ with the ones considered in the splitting at order $n-1$. There are different approaches to solve the double counting, known as ME-PS matching. The most common strategy is known as slicing, which defines a matching scale where the higher energy region is covered only by the \acrshort{MElabel} while any additional parton with energy below the scale is vetoed and only covered with the \acrshort{PSlabel} algorithm. With this strategy, both energy regions are described with the corresponding optimal algorithm.

\subsection{Hadronisation}

The hadronisation process starts when the energy of the \acrshort{PSlabel} emissions is low enough to reach the hadronisation scale ($\sim$1~GeV), where the perturbative regime of \acrshort{QCD} is not valid. At that point, the partons from the \acrshort{PSlabel} have defined momentum, flavour and color and furhter description of the emissions has to rely on phenomenological models. The process consists on a reconstruction algorithm that groups together the partons into different hadrons, that can further split, until all partons are confinend into stable hadrons. 

The two most widely used models are: the Lund string model %https://www.sciencedirect.com/science/article/pii/0370157383900807?via%3Dihub
and the cluster model. %https://link.springer.com/article/10.1140/epjc/s2004-01960-8
In the first, the quark-antiquark pair colour interaction is described as a string with a potential assumed to be linearly increasing with the distance, emulating the \acrshort{QCD} potential. The string then splits forming new quark-antiquark pairs when the energy stored passes the quark-antiquark total mass, forming hadrons which momentum is determined from the initial momentum by a fragmentation function. The momentum of the hadron as a fraction . On the otherhand, the second model is based on forcing the final state gluons to split into quark-antiquark pairs and then grouping all quarks in colour-singlet clusters, allowed to decay and split into smaller clusters or hadrons. For both models, the process is repeated iteratively until only stable hadrons remain.

\subsection{Pile-up and underlying event}

Other interactions aside the hard-scattering event have to be included in the \acrshort{MClabel} simulations to properly model the \acrshort{LHClabel} collisions, the pile-up and the underlying event. Both sources mainly consist of soft \acrshort{QCD} interactions, the first arising from other protons colliding in the same or previous bunch-crossing while the second being the interaction of the other partons that do not originate the hard-scattering process. Both mainly consist of soft \acrshort{QCD} interactions in the forward regime, close to the beam axis, and the description is based of the combination of phenomenological models and the configuration of the \acrshort{LHClabel} beam. In the especial case of out-of-time pileup (interactions from previous bunch-crossings), the simulation has to take into account the time response of the detector.

\subsection{Monte Carlo simulation and generators}

\acrshort{MClabel} generators are dedicated software tools to perform the \acrshort{MClabel} simulations, based on pseudo-ranom numbers to generate the events from the predicted distributions. They are generally classified according to which of the steps of the simulation can perform, with general purpose generators being capable of simulating the whole event process, while dedicated generators target specific parts of the chain, such as the \acrshort{MElabel} or the \acrshort{PSlabel} computation.

The full process involving \acrshort{MElabel} generation, \acrshort{PSlabel}, underlying event, hadronisation and fragmentation can be simulated by \acrshort{MClabel} generators like \PYTHIA~8 %https://www.sciencedirect.com/science/article/pii/S0010465515000442?via%3Dihub
, \HERWIG~7 %https://link.springer.com/article/10.1140/epjc/s10052-008-0798-9 https://link.springer.com/article/10.1140/epjc/s10052-016-4018-8
or \SHERPA %https://scipost.org/10.21468/SciPostPhys.7.3.034
. However, \PYTHIA~8 provides leading order calculations which are often not
sufficient and hence, the generator is tipically used to compute the \acrshort{PSlabel} process, which is based on the Lund string model. On the other hand, \HERWIG~7 provides many \acrshort{MElabel} at NLO, however since the fraction of negative event weights can be quite large (up to $\sim40\%$ for certain generator setups), the generator is also tipically used for \acrshort{PSlabel} computation, based on the cluster model. \POWHEGBOX %https://iopscience.iop.org/article/10.1088/1126-6708/2004/11/040 https://iopscience.iop.org/article/10.1088/1126-6708/2007/11/070 https://link.springer.com/article/10.1007/JHEP06(2010)043 https://journals.aps.org/prd/abstract/10.1103/PhysRevD.91.094003 https://iopscience.iop.org/article/10.1088/1126-6708/2007/09/126
and \MGMCatNLO %https://iopscience.iop.org/article/10.1088/1126-6708/2007/09/028
are examples of other generators that are especially designed to provide accurate high-order \acrshort{MElabel} calculations which are tipically interfaced with \PYTHIA~8 or \HERWIG~7 for the simulation of \acrshort{PSlabel} and hadronisation. 

More in detail, these tools have parameters to describe the non-perturbative processes that can be tuned using collision data. The most common tunes used by the \acrshort{ATLASlabel} collaboration are the A14 %https://cds.cern.ch/record/1966419
parameters combined with \textit{NNPDF3.0LO} \acrshort{PDFlabel}s set %https://www.sciencedirect.com/science/article/pii/S0550321312005500?via%3Dihub 
for \PYTHIA~8 and the H7UE set % repeated https://link.springer.com/article/10.1140/epjc/s10052-016-4018-8
with the \textit{MMHT2014LO} \acrshort{PDFlabel}s sets %https://link.springer.com/article/10.1140/epjc/s10052-015-3397-6
for \HERWIG~7. Throughout this thesis different combinations of \acrshort{MClabel} generators and settings, which are detailed in the corresponding chapters and, if not stated otherwise, share the same parameters. The mass of the top quark is set to $m_t=172.5$~GeV, the mass of the Higgs boson to $m_H=125$~GeV and the mass of the $b$-quark to $m_b=4.8$~GeV for \PYTHIA~8, to $m_b=4.5$~GeV for \HERWIG~7 and to $m_b=4.75$~GeV for \SHERPA. The simulation involving $b$- and $c$-hadron decays is performed with \EVTGEN %https://www.sciencedirect.com/science/article/pii/S0168900201000894?via%3Dihub
(except for \SHERPA). 

\section{Detector simulation}

With the proton-proton collisions simulated and the final-state stable particles defined, the remaining step is to simulate the interactions with the detector. The full \acrshort{ATLASlabel} detector simulation is performed in two steps: first, the \acrshort{ATLASlabel} detector response of the \acrshort{MClabel} output is simulated and then the signals are reconstructed using the same algorithms used in real data. \textcolor{red}{Figure} depicts the different steps both for data and simulated \acrshort{MClabel} events.

The \GEANT~4 package %https://linkinghub.elsevier.com/retrieve/pii/S0168900203013688 
is a widely used in physics to simulate the propagation and interaction of particles with matter. The simulation that includes all the geometry of the \acrshort{ATLASlabel} sub-detector systems with \GEANT~4 is referred to \textit{Full Simulation}~(FullSim), which is computationally expensive (several minutes per event) but gives the most accurate result. As more than 90\% of the dedicated CPU time is spent on the calorimeter simulations, alternatives are used in practice. The \textit{AtlFast-II} (AF-II) simulation is performed with faster simulation algorithms for the calorimeter simulation, \acrshort{ATLASlabel} Fast Calorimeter Simulation~(\textsc{FastCaloSim}) % https://cds.cern.ch/record/1300517
, and for the \acrshort{IDlabel} simulation, Fast \acrshort{ATLASlabel} Tracking Simulation~(\textsc{Fatras}) % https://cds.cern.ch/record/1091969
. The rest of systems are simulated with \GEANT~4 adding to significantly less CPU time while maintaining an adequate level of accuary. Finally, the normalisation of a \acrshort{SMlabel} process is normally chosen according to the cross-section at the highest-order available and other corrections are applied in the form of scale factors (SFs), derived from the ratio between data and \acrshort{MClabel} in specific calibration regions.

%https://arxiv.org/abs/1005.4568
The concept of \textit{reconstruction} refers to the use of algorithms for the identification of physics objects from the signals recorded in the different sub-systems of the detector. The physics processes described in this thesis produce electrons, muons, taus, photons, neutrinos and quarks in the final state. However, not all of these listed particles can be directly observed, as quarks form cascades of hadronic particles, neutrinos leave without interacting with \acrshort{ATLASlabel} and tau leptons decay before reaching the detector. \textcolor{red}{Figure} illustrates the interaction of different particles with the \acrshort{ATLASlabel} detector. Charged particles produce a track in the \acrshort{IDlabel}, electrons and photons shower in the \acrshort{EMlabel} calorimeter, hadrons shower in the hadronic calorimeter and muons leave signals in the muon spectrometer.

The reconstruction of the different physics objects used in this thesis analyses is described in the following chapter.

\section{Base objects}

The fundamental blocks used in the reconstruction algorithms are tracks, vertices and topo-clusters (or calorimeter energy clusters). All physics objects are composed by these blocks and introduced in the following section.

\subsection{Tracks and vertices}

Tracks are objects produced by charged particles interacting in the \acrshort{IDlabel} and used to identify their trajectory. The reconstruction consists in grouping hits in the different tracking sub-systems and requiring different criteria to ensure the quality of the tracks. The tracks that originate from the hard-scattering are referred to as primary tracks, and the origin of the track (vertex) is referred to as the  \acrfull{PVlabel}~(\acrshort{PVlabel})

As a first step, hits are built from groups of pixels and strips that reach a threshold energy deposit starting from the inner layers \acrshort{IDlabel}. The seed to reconstruct a track consists in three hits in the silicon detector, and then hits from the outer layers of the tracker compatible with the trajectory are added iteratively. When adding points, a score is assigned to the track to quantify the correctness of the track trajectory and suppresses the contribution of random collections of hits (or fake tracks). Then, a dedicated algorithm evaluates the different seeds to limit shared hits, which typically indicate wrong assignments. In addition, quality criteria are applied where tracks are required to have $\pT>500$~MeV, $\abs{\eta}<2.5$, minimum of seven pixel and \acrshort{SCTlabel} clusters, a maximum of either one shared pixel cluster or two \acrshort{SCTlabel} on the same layer, no more than one missing expected hit (or hole) in the pixel detector and a maximum of two holes in both pixel and \acrshort{SCTlabel}. Also, requirements in the transverse impact parameter calculated with respect to the beam position, $\abs{d_0}<2$~mm, and related to $z_0$, the longitudinal difference between the \acrshort{PVlabel} and $d_0$ along the beam, $\abs{z_0 \sin\theta} <3$~mm. As a last step, \acrshort{TRTlabel} hits are added to the tracks after extrapolation.

Vertices are of particular interest as they are the origin of the charged particles or interactions. The \acrshort{PVlabel} is the most important, as denotes the origin of the hard-scattering interaction, but secondary vertices are also characteristic of long-lived particles or for heavy-flavour tagging.\todo{not talked yet}

For a given event, the \acrshort{PVlabel}s are reconstructed iteratively from tracks using a dedicated vertex finding algorithm. From a set of quality tracks, a candidate position is defined and the compatibility with the set of tracks in terms of weights is evaluated in order to recompute the vertex position. In each step then, the tracks that are less compatible are given smaller weights and, after the convergence of the optimal vertex position, are left unassigned and remain as input for the following vertex. The \acrshort{PVlabel} is defined as the vertex with the largest $\pT^2$ sum. 

\subsection{Topological clusters}

Topological cell clusters, or topo-clusters, are objects reconstructed iteratively from calorimeter information and are the first step in the reconstruction of electrons, photons and hadrons. The seed consists of calorimeter cells which readout signal is four times higher than the background noise, and neighbour cells are added if the ratio is higher than two. As a last step, an extra layer is added regardless of the signal-to-background ratio. \todo{a little bit weak?}

\section{Jets}

Jets are the cone-shaped collimated showers formed by the hadronic cascades that originate from the complex interactions of quarks and gluons when travelling through the detector. These objects are essential for physics analyses with partons in the final state, especially $b$-quarks, which jets have particular properties that can be used to characterise them with great efficiency. Nevertheless, the kinematic properties of the cascades are challenging to define, as they can contain information from one or multiple final state partons and from the hard-scattering or other radiation processes. There are different possible definitions that depend of dedicated algorithms which group calorimeter information and do not depend on common \acrshort{QCD} effects. Jet algorithms are collinear safe, referred to the jet not changing if two constituents are merged forming one with double the momentum (or vice-versa), and infrared safe, meaning that the reconstruction is not affected by adding low \pT\ particles.

\subsection{Reconstruction}

The jet reconstruction is typically performed using the anti-k$_t$ algorithm. %https://iopscience.iop.org/article/10.1088/1126-6708/2008/04/063
. This family of algorithms merges clusters based on a relative distance defined as,

\begin{equation}
    d_{i,j} = \min (p_{\text{T},i}^{2n},p_{\text{T},j}^{2n}) \frac{\Delta R_{i,j}}{R^2}
\end{equation}

with $p_{\text{T},i/j}$ the \pT\ of the cluster $i$ and $j$, $\Delta R_{i,j}$ the angle separation between them, $R$ the chosen radius parameter that sets the size of the jet and $n$ chosen integer that defines the \pT\ dependance of $d_{i,j}$. The decision to combine clusters or to define a cluster as a jet comes from comparing the $d_{i,j}$ value with the beamspot distance, $d_{i,B} = p_{\text{T},i}^{2n}$. Clusters are grouped if $d_{i,j} < d_{i,B}$, otherwise the cluster $i$ is defined as a jet, in an iterative process until all input clusters are used. The anti-k$_t$ algorithm is defined by setting $n=-1$, which groups with higher priority the high energy clusters, and leads to a cone-shape around the highest object. This feature can be observed in \textcolor{red}{Figure}.

Various jet collections based on the anti-k$_t$ algorithm are used in \acrshort{ATLASlabel}, two of them are used in this thesis: EMTopo jets and Pflow jets.

\subsubsection{EMTopo jets}

The so-called EMTopo jets were the primary jet collection used in physics analyses in \acrshort{ATLASlabel} before the end of Run~2. The reconstruction is performed at the EM energy scale only using topo clusters %https://doi.org/10.1103/PhysRevD.96.072002
with the anti-k$_t$ algorithm implemented in the \textit{FASTJET} software package %https://link.springer.com/article/10.1140/epjc/s10052-012-1896-2
. The jets used in this thesis are reconstructed with the radius parameter $R = 0.4$ with requirements in $\pT > 25$~GeV and $\abs{\eta} < 2.5$. The EMtopo jets are calibrated in several steps summarised in \textcolor{red}{Figure} %https://arxiv.org/pdf/2007.02645.pdf
. After the jet reconstruction, the jet direction is modified such that the jet originates from the primary vertex. Then, energy corrections based on pile-up are applied subtracting the average energy due to in-time pile-up and other residual corrections that depend on the number of \acrshort{PVlabel} and bunch crossings. After, absolute calibrations are applied to the \acrlong{JESlabel}~\acrshort{JESlabel} and $\eta$ derived from dedicated dijet \acrshort{MClabel} events. Then, a global sequential calibration is set to improve the \pT\ resolution and the associated
uncertainties from the jet fluctuations that can arise from various initial factors like the flavour or energy of the original parton. The final step is the in-situ calibration which is only applied to data, extracted from \pT and $\eta$ comparisons to known well-modelled \acrshort{MClabel} that include central jets in dijet events, $\gamma/Z+jets$ or multijet events. 

\subsubsection{PFlow jets}

Particle Flow jets, known as PFlow jets, were introduced during Run~2 and combine tracking and calorimeter information. This collection of jets has improved energy and angular resolution compared to EMTopo jets and enhanced reconstruction and stability against pile-up. The reconstruction %https://link.springer.com/article/10.1140/epjc/s10052-017-5031-2
is also based on the anti-k$_t$ algorithm with $R=0.4$, and the first step consists in matching the tracks (from the \acrshort{IDlabel}) from charged particles to the topo-clusters. The energy deposits of the matched topo-clusters are replaced by the corresponding track momentum. Then, the resulting topo-clusters and the tracks matched to the \acrshort{PVlabel} are used as input of the anti-k$_t$ algorithm. The jets are calibrated like the EMTopo jets in the range 20~GeV $<\pT<1500$~GeV. 

\subsection{Jet tagging}

Jet or flavour tagging consists in identifying the parton flavour that generated the signal reconstructed as the jet. Efficient tagging is essential for analyses studying processes with $b$- or $c$-quarks in their final state (knows as heavy flavour quarks), as it is additional information which can be used to select events based on the flavour of their jets and improve the selection of the signal.

Jets originating from the hadronisation of $b$-quarks, or $b$-tagged jets, leave a distinct signal due to the properties of $b$-hadrons: lifetime of $\sim 10^-12$~s (decay after 2.5~mm with a momentum of 30~GeV), mass of $\sim 5$~GeV and high decay multiplicity (including semi-leptonic decays). \textcolor{red}{Figure} shows a scheme of a typical signal, that includes displaced tracks from the \acrshort{PVlabel} with large $d_0$.
The signal of the $c$-hadrons is similar but not identical as the lifetime, mass and decay multiplicity are lower, which makes the distinction between these two kinds of jets difficult. The last type of jet is referred to light-flavour jets, which signal originates directly from quark fragmentation and can be easily separated from $b$-jets. However, other phenomena like long-lived particles, photon conversion or low quality tracks can also prompt displaced vertices and tracks.

\subsubsection{Algorithms}

Flavour tagging algorithms use the properties of a given jet to return a score, referred to as output discriminant, which indicates how likely the input jet is considered to be a $b$-, $c$- or $light$-jet. Two main taggers are used in \acrshort{ATLASlabel}: the MV2c10 tagger which was the default option for EMTopo jets, and the DL1r tagger that is the recommendation for PFlow jets.

The MV2c10 tagger  %http://cdsweb.cern.ch/record/2037697 
is a MV2 algorithm, which relies on boosted decision trees trained with several kinematic and other trigger taggers as inputs. This particular tagger was trained with \ttbar\ and $Z'$ events, to cover a large \pT\ spectrum, and $b$-jets defined as signal while the background was defined to consist of 7\% $c$-jets and 93\% light-jets.

The DL1r tagger



\subsubsection{Working points}

The full spectrum of the final $b$-tagging discriminant is not directly used in physics analyses due to the complexity of the calibration. Instead, four different $b$-tagging \acrlong{WPlabel}~(\acrshort{WPlabel}) are defined based on the $b$-jet acceptance efficiency evaluated on a \ttbar\ sample: 60\%, 70\%, 77\% and 85\%, which are often referred to as \textit{Very Tight},\textit{Tight},\textit{Medium} and \textit{Loose} operating points, respectively. Most of the $c$- and light-jets do not pass the 85\% \acrshort{WPlabel}, ending up in the $b$-tagging efficiency between 85\% and 100\%. Meanwhile, the jets that pass the 60\% \acrshort{WPlabel} mainly consists in $b$-jets. This criteria is important when defining the $b$-jets for event selection, as the $b-$jets misidentification, so $c$- and $light$-jet acceptance inefficiency, improves for lower $b$-jet efficiency working points, therefore rejecting more background but with lower signal statistics. On the other hand, the pseudo-continuous b-tagging \acrshort{WPlabel}, so the \acrshort{WPlabel} that a jet passes, is additional information that can be used to further refine the selection or in multivariate methods.

\section{Electrons}

Electrons are reconstructed using the information of the ID and the calorimeter system. The typical
signature of an electron is that they leave a track in the ID and are then absorbed in the electromagnetic calorimeter where they leave an electromagnetic shower. The ttH¯ (bb¯) analysis and the flavour
tagging studies in this thesis use the algorithms described in detail in Ref. [126, 127]

The electron object is constructed using a dynamic clustering algorithm with variable-size clusters,
so-called superclusters. The reconstruction is performed in the region |etacluster| < 2.47 excluding the
transition region of the barrel and end-cap (1.37 < |etacluster| < 1.52).
At first, topo clusters (described in sec. 6.1.3) are selected and loosely matched to ID tracks. Simultaneously, the conversion vertices matched to the topo clusters are built. Next, the superclusters are
built from matched clusters and a first position correction and energy calibration is applied. Tracks
are then matched to the electron superclusters. The energy scale and resolution of electrons are
calibrated using Z → ee decays and validated in Z → ``gamma decays [127]. In addition, the energy resolution of the electron is optimised using a multivariate regression algorithm based on the properties
of shower developments in the electromagnetic calorimeter.

Further quality criteria are required for an electron object, passing several identification selections
to improve the purity of the selected objects. The prompt electrons are identified using a likelihood
discriminant which uses quantities measured in the ID and the electromagnetic calorimeter. These
quantities are chosen such that they discriminate well prompt isolated electrons from other energy
deposits like jets, converted photons or genuine electrons stemming from heavy-flavoured hadron
decays. Important observables for the likelihood calculation are based on the track quality in the ID,
the lateral and longitudinal development of the electromagnetic shower described by shower shape
variables as well as the particle identification in the TRT. The algorithm uses probability density
functions as input which are derived for the signal from Z → ee (ET > 15 GeV) and J/psi → ee
(ET < 15 GeV) events.
The efficiency of the electron identification is provided in three operating points: Loose, Medium
and Tight, yielding different purities. Figure 6.4 shows the data efficiency as a function of ET and
as a function of the average number of bunch crossings for all three operating points. They are
all optimised in 9 |eta| and 12 ET bins. For this thesis the Medium and Tight operation points are

Electrons are typically required to be spatially separated from other particles. There are two kinds of
isolation variables: calorimeter-based and track-based.
The calorimeter-based isolation is calculated via the sum of the transverse energy of positive-energy
topo clusters with a barycentre falling in a deltaR = 0.2 of the electron barycentre (other than the
electron clusters themselves). In addition, leakage and pile-up corrections are applied.
For the track-based isolation the sum of the transverse momentum of tracks within a cone centred
around the electron track are considered, where the cone radius decreases with pT. Moreover, only
tracks are taken into account which have pT > 1 GeV and |eta| < 2.5 as well as satisfy certain track
quality criteria and have a loose vertex association2
. In this thesis the Gradient isolation working
point (WP) is chosen which gives an efficiency of 90% at pT = 25 GeV and 99% at pT = 60 GeV
uniform in eta

\section{Muons}

Muons leave a track in the detector and traverse the calorimeter system typically without significant
energy loss. Therefore, the muon is mainly reconstructed in the ID and the MS sub-detector systems.
The RUN II muon reconstruction and performance is described in detail in [128]

The muon reconstruction has two stages: first the independent reconstruction in the ID and MS
and secondly the combination of the two to form the muon tracks. The reconstruction in the ID is
performed as for any other charged particle.
In the MS at first a search for hit patterns is performed in each muon chamber to form segments. In
the MDTs and nearby trigger chambers, hits are aligned on the trajectory in the bending plane of
the detector using a Hough transformation and the segments are reconstructed with a straight line
fit to hits found in each layer. The hits of the RPCs and TGCs provide measurements for the plane
orthogonal to the bending plane and in the CSCs a combinatorial search in the eta and phi plane is
utilised to build the segments. Given this information, muon track candidates are constructed by
fitting segments from different layers using a global chi
2 fit.
The combined reconstruction is based on various algorithms defining four different types of muons.
The combined (CB) muons are first independently reconstructed in the ID and MS and then their
information is combined with an outside-in approach, extrapolating reconstructed tracks from the MS
to the ID (complementary an inside-out approach is also used). The segment-tagged (ST) muons are
mainly reconstructed from tracks in the ID extrapolated to typically one track segment in the MDTs
and CSCs. The third type are the calorimeter-tagged (CT) muons where an ID track is matched to an
energy deposit in the calorimeter compatible with a minimal ionising particle. This muon type has
the lowest purity and is optimised for the region |eta| < 0.1 with 15 GeV < pT < 100 GeV. There
are also extrapolated (ME) muons that are only reconstructed in the MS extending the acceptance to
2.5 < |eta| < 2.7 but they are not used in this thesis

Similarly to the electron identification, the muon identification is performed applying quality criteria
to suppress background processes.The goal is to identify prompt muons with high efficiency and a
good momentum resolution which requires a certain amount of hits in the ID and the MS. To cover
different needs of physics analyses, four different muon WPs are available: Loose, Medium, Tight
and high pT. For the scope of this thesis, the Medium and Loose WPs are used.
For the Medium WP only combined muons are taken into account. The combined muons are required
to have three or more hits in at least two MDT layers except for the |eta| < 0.1 region where only one
MDT layer is sufficient combined with no more than one hole layer due to a gap in the MS. This WP
tries to minimise systematic reconstruction and calibration systematic uncertainties associated with
the muon. The Medium WP reconstruction efficiency with pT > 20 GeV is 96.1%

The Loose WP maximises the reconstruction efficiency with good-quality muon tracks. In this case,
all muon types are utilised. In fact, the combined muons are used as they are from the Medium
selection. Additionally, the calorimeter-tagged and segment-tagged muons are taken into account for
|eta| < 0.1. The reconstruction efficiency for muons with pT > 20 GeV is 98.1%.
Figure 6.5 shows the reconstruction efficiency measured in data for the two described WPs obtained
from Z → µµ and J/psi → µµ event

Analogously to the electron isolation strategy, the muon isolation is assessed via track- and calorimeter-based variables with very similar definitions. The track-based variable p
varcone30
T
is the scalar pT sum
of all tracks, excluding the muon track, with pT > 1 GeV in a radius of deltaR = min(10 GeV/pµ
T
, 0.3)
around the muon transverse momentum p
µ
T
. The calorimeter isolation variable is constructed from
the sum of transverse energies around the muon track, as described for electrons. However, for the
scope of this thesis the isolation WP FixedCutTightTrackOnly is utilised which is only using the
track-based isolation satisfying p
varcone30
T
/pµ
T < 0.06. The isolation efficiencies are measured using
Z → µµ events.

\section{Taus}

tau-leptons can decay either leptonically (into electrons or muons) or hadronically. The leptonic decays
are similarly reconstructed as electrons or muons. The taus decays with a hadronic final state are seeded
by jets which are required to have pT > 10 GeV and |eta| < 2.5 excluding the barrel-end-cap transition
region [129]. Tau leptons are calibrated to correct their energy deposit in the detector to the average
value at generator level. The tau identification is based on BDTs discriminating tau-jets from the quark-and gluon-initiated background jets. Three different efficiency WPs are defined: Loose, Medium
and Tight. In this thesis the Medium tau-WP and the requirement pT > 25 GeV is used as well as an
isolation criterion of deltaRy < 0.2 between a tauhad candidate and any selected electron or muon.

\section{Missing transverse energy}

The missing transverse momentum, also denoted as \MET\ is the transverse component of the negative vector sum of the fully calibrated objects (electrons, muons, photons, hadronically decaying taus and jets) as well
as soft objects [130] from additional tracks associated to the PV. In an ideal detector, the the sum of four-momenta of all particles produced is equal to the net momentum of the initial collision, implying that the net momentum in the transverse plane of the collision has to be zero, $\MET=0$. Nevertheless, the net momentum is not null as particles like neutrinos can leave the detector without depositing energy or others can interact with the detector in regions not covered by electronics. For analyses with neutrinos in the final state, it typical to consider that the transverse energy carried by the neutrinos is the $\MET$, which allows their reconstruction.